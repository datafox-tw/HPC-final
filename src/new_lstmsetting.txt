src/model_train_lstm.py 目前預設不再餵任何 future_covariates，完全杜絕原本的資料洩漏來源。如果仍想利用協變數，可加上 --covariate_mode lagged --covariate_lag 1，程式會先把 cov 在時間軸上往後移一天，讓模型看到的永遠是「前一日」的資訊，再以 Darts future_covariates 介面送進 RNN。不論訓練或驗證都會用相同的 lag 處理。
125:180:src/model_train_lstm.py
parser.add_argument("--covariate_mode", choices=["none","lagged"], default="none", ...)
...
future_covariates = None
if args.covariate_mode == "lagged":
    future_covariates = _build_lagged_covariates(train_covs, args.covariate_lag)
...
model.fit(**fit_kwargs)
src/predict_lstm.py 同步加入 --covariate_mode/--covariate_lag，推論時會依照相同邏輯（lag 再串接）準備協變數；若未啟用則完全不傳入，確保評估與訓練一致。
16:120:src/predict_lstm.py
parser.add_argument("--covariate_mode", choices=["none","lagged"], default="none", ...)
...
train_covs_processed = _build_lagged_covariates(train_covs, args.covariate_lag)
...
history_covariates = cov_builder(idx) if args.covariate_mode == "lagged" else None

如何使用：
完全關閉 cov（預設）
   python src/model_train_lstm.py --data ... --covariate_mode none ...
   python src/predict_lstm.py     --data ... --covariate_mode none ...
   這樣 LSTM 只看 target（含 GARCH 通道），與 TSMixer 一樣不會接觸未來特徵。
安全啟用 lagged cov（只想用前一天資訊）
   python src/model_train_lstm.py --covariate_mode lagged --covariate_lag 1 ...
   python src/predict_lstm.py     --covariate_mode lagged --covariate_lag 1 ...
   lagged_covariates 會把每個時間點的 cov 值替換為上一日的數值，首日自動補 0，確保模型在時間 t 只看得到 t-1 的特徵；評估時沿用相同處理，不會誤用當日/未來資訊。
若之後需要更長的 lag（例如用 t-2 的特徵預測 t），只要把 --covariate_lag 換成 2、3… 即可，但需確保序列長度足夠。這份調整後，即使 lambda 設很大，LSTM 的提升也必須來自模型本身，而非洩漏的 cov。
